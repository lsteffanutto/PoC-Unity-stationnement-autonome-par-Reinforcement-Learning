behaviors:
  CarAgent:
    trainer_type:   ppo
    hyperparameters:    
      batch_size:   1024
      buffer_size:  4096
      learning_rate:    0.0001
      beta: 0.001
      epsilon:  0.2
      lambd:    0.95
      num_epoch:    3
      learning_rate_schedule:   linear
    network_settings:   
      normalize:    True
      hidden_units: 512
      num_layers:   3
    reward_signals: 
      extrinsic:    
       gamma:  0.99
       strength:   1.0
      curiosity:    
        gamma:  0.99
        strength:   0.02
        network_settings:   
          normalize:    False
          hidden_units: 256
          num_layers:   2
          vis_encode_type:  simple
          memory:   None
          goal_conditioning_type:   hyper
        learning_rate:  0.0003
        encoding_size:  None
      gail: 
        gamma:  0.99
        strength:   0.01
        network_settings:   
          normalize:    False
          hidden_units: 128
          num_layers:   2
          vis_encode_type:  simple
          memory:   None
          goal_conditioning_type:   hyper
        learning_rate:  0.0003
        encoding_size:  None
        use_actions:    False
        use_vail:   False
        demo_path:  C:\Users\steffanutto\Desktop\KARlab_UC3_Unity\POC1\Assets\Demonstrations\BCScenario2FT.demo
    max_steps:  200000000
    time_horizon:   32
    summary_freq:   50000
    behavioral_cloning: 
      demo_path:    C:\Users\steffanutto\Desktop\KARlab_UC3_Unity\POC1\Assets\Demonstrations\BCScenario2FT.demo
      steps:    150000
      strength: 0.5
      samples_per_update:   0
      num_epoch:    None
      batch_size:   None

